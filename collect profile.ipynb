{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T22:30:32.997640Z",
     "start_time": "2019-04-09T22:30:32.994518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T22:30:50.056155Z",
     "start_time": "2019-04-09T22:30:50.051997Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'linux_ckl'\n",
    "PROJECT_PATH = os.getcwd().rsplit(f'/{PROJECT_NAME}', 1)[0] + f'/{PROJECT_NAME}'\n",
    "\n",
    "LINUX_REPO_BASE = os.path.join(PROJECT_PATH, 'repo')\n",
    "SNAPSHOTS_BASE = os.path.join(PROJECT_PATH, 'snapshots')\n",
    "DATA_IN = os.path.join(PROJECT_PATH, 'data_in')\n",
    "os.makedirs(DATA_IN, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T22:31:38.038016Z",
     "start_time": "2019-04-09T22:31:38.033535Z"
    }
   },
   "outputs": [],
   "source": [
    "VERSIONS = {\n",
    "#     'v2.6.12-rc2':'2005-04-16 15:20:36 -0700',\n",
    "#     'v2.6.21' : '2007-04-25 20:08:32 -0700',\n",
    "    'v2.6.31':'2009-09-09 15:13:59 -0700',\n",
    "    'v3.0':'2011-07-21 19:17:23 -0700',    \n",
    "#     'v3.11':'2013-09-02 13:46:10 -0700',        \n",
    "    'v4.0':'2015-04-12 15:12:50 -0700',            \n",
    "#     'v4.13':'2017-09-03 13:56:17 -0700',\n",
    "    'v5.0':'2019-03-03 15:21:29 -0800'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('v2.6.31', 'v3.0'),\n",
       " ('v2.6.31', 'v4.0'),\n",
       " ('v2.6.31', 'v5.0'),\n",
       " ('v3.0', 'v4.0'),\n",
       " ('v3.0', 'v5.0'),\n",
       " ('v4.0', 'v5.0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_diff_snapshots():\n",
    "    return [(v1, v2) for v1, v2 in  combinations(VERSIONS.keys(), 2)]\n",
    "\n",
    "        \n",
    "DIFFS = generate_diff_snapshots()\n",
    "DIFFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T22:31:40.414678Z",
     "start_time": "2019-04-09T22:31:40.411212Z"
    }
   },
   "outputs": [],
   "source": [
    "def tool_file_path(version, tool):\n",
    "    return os.path.join(DATA_IN, f'{version}.{tool}')\n",
    "\n",
    "def snap_folder_path(version):\n",
    "    return os.path.join(SNAPSHOTS_BASE, version)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_collect_msg(msg):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_decorator(function):\n",
    "    def wrapper(input_folder, output_file, overwrite = False):\n",
    "        assert os.path.exists(input_folder) \n",
    "        assert os.path.isdir(input_folder) \n",
    "\n",
    "        fname = function.__name__\n",
    "        \n",
    "        if os.path.exists(output_file) and not overwrite:\n",
    "            log_collect_msg(f'{fname} SKIP existing file: {output_file}')\n",
    "            return \n",
    "\n",
    "        log_collect_msg(f'{fname} is about to create {output_file} for folder {input_folder}')\n",
    "        function(input_folder, output_file)\n",
    "        \n",
    "        if os.path.exists(output_file):\n",
    "            log_collect_msg(f'{fname} has created an output file. Size: {os.stat(output_file).st_size} bytes.')\n",
    "        else:\n",
    "            log_collect_msg(f'{fname} has FAILED to create output file')        \n",
    "            \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_folder_tidy_paths(input_folder, extensions_list = None):\n",
    "    for root, subdirs, files in os.walk(input_folder):\n",
    "        for f in files:\n",
    "            _, ext = os.path.splitext(f)\n",
    "            if extensions_list and ext.lower() not in extensions_list: \n",
    "                continue\n",
    "            rel_path = os.path.relpath(root, input_folder)\n",
    "            yield os.path.join(rel_path, f).lower(), os.path.join(rel_path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_lines(f):\n",
    "    with open(f, encoding='latin-1', errors='ignore') as fin:\n",
    "        lines = fin.readlines()\n",
    "        empty_lines_count = sum([1 for l in lines if 0 == len(l.strip())])\n",
    "        return len(lines), empty_lines_count\n",
    "    \n",
    "\n",
    "@profile_decorator\n",
    "def collect_lines(input_folder, output_file, overwrite = False):\n",
    "    def _collect(input_folder):\n",
    "        for tidy_path, raw_path in enumerate_folder_tidy_paths(input_folder):\n",
    "            lines, empty_lines = get_file_lines(os.path.join(input_folder, raw_path))\n",
    "            yield (tidy_path, lines, empty_lines)\n",
    "\n",
    "    df = pd.DataFrame(data=_collect(input_folder), \n",
    "                      columns=['tidy_path', 'lines_count', 'empty_lines_count'])\n",
    "\n",
    "    df.to_csv(output_file, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_diff_pairs(left_folder, right_folder, output_file,\n",
    "                       exclude_exact_match, extensions_list, similar_exts, \n",
    "                       func_compare_paths, overwrite = False):\n",
    "    assert os.path.exists(left_folder) and os.path.isdir(left_folder) \n",
    "    assert os.path.exists(right_folder) and os.path.isdir(right_folder) \n",
    "\n",
    "    if os.path.exists(output_file) and not overwrite:\n",
    "        log_collect_msg('collect_diff_pairs SKIP existing file ' + output_file)\n",
    "        return \n",
    "    \n",
    "    log_collect_msg(f'collect_diff_pairs is about to create {output_file}')\n",
    "    \n",
    "    left_files = dict(enumerate_folder_tidy_paths(left_folder, extensions_list))\n",
    "    right_files = dict(enumerate_folder_tidy_paths(right_folder, extensions_list))\n",
    "    \n",
    "    def is_similar_ext(ext1, ext2): return any([ext1 in sim_set and ext2 in sim_set for sim_set in similar_exts])    \n",
    "\n",
    "    def choose_left_candidate(right_file, left_files_names):\n",
    "        right_fname, right_ext = os.path.splitext(os.path.basename(right_file))\n",
    "        \n",
    "        best_ratio, best_left = 0, None\n",
    "        for left_file in sorted(left_files_names[right_fname]):\n",
    "            if left_file == right_file:\n",
    "                if exclude_exact_match:\n",
    "                    return 0, None\n",
    "                else:\n",
    "                    return 1, left_file\n",
    "\n",
    "            left_fname, left_ext = os.path.splitext(os.path.basename(left_file))\n",
    "            if not is_similar_ext(left_ext, right_ext):\n",
    "                continue\n",
    "\n",
    "            candidate_ratio = func_compare_paths(left_file, left_fname, left_ext, right_file, right_fname, right_ext)\n",
    "            if candidate_ratio > best_ratio: \n",
    "                best_ratio, best_left = candidate_ratio, left_file\n",
    "        \n",
    "        return best_ratio, best_left\n",
    "\n",
    "    def match_right_files(left_files, right_files):\n",
    "        left_files_names = defaultdict(list)\n",
    "        for f in left_files:\n",
    "            fname, _ = os.path.splitext(os.path.basename(f))\n",
    "            left_files_names[fname].append(f)\n",
    "\n",
    "        for right_file in tqdm(right_files, total=len(right_files)):\n",
    "\n",
    "            best_ratio, best_left = choose_left_candidate(right_file, left_files_names)\n",
    "            if best_left is None:\n",
    "                continue\n",
    "\n",
    "            yield best_left, left_files[best_left], right_file, right_files[right_file], best_ratio\n",
    "    \n",
    "    df = (pd.DataFrame(data=match_right_files(left_files, right_files), \n",
    "                      columns=['File from', 'Raw File from', 'File to', 'Raw File to', 'Ratio'])\n",
    "              .set_index(['File from', 'File to']))\n",
    "    \n",
    "    df.to_csv(output_file, sep=\";\")\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        log_collect_msg(f'collect_diff_pairs has created an output file. Size: {os.stat(output_file).st_size} bytes.')\n",
    "    else:\n",
    "        log_collect_msg(f'collect_diff_pairs has FAILED to create output file')        \n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_paths_longest_folder_seq(left_file, left_fname, left_ext, right_file, right_fname, right_ext):\n",
    "    if left_file == right_file:\n",
    "        return 1\n",
    "    \n",
    "    if left_fname != right_fname:\n",
    "        return 0\n",
    "    \n",
    "    # Remove all empty elements in list after split to handle edge cases\n",
    "    fp1 = list(filter(lambda x: x!= \"\", left_file.split(\"/\"))) \n",
    "    fp2 = list(filter(lambda x: x!= \"\", right_file.split(\"/\"))) \n",
    "    sm = SequenceMatcher(None, fp1, fp2)\n",
    "    return sm.ratio()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tool_diff(left_folder, right_folder, \n",
    "                      diff_input_file, output_file, \n",
    "                      tool_diff_names, func_tool_diff, overwrite = False):\n",
    "    \n",
    "    assert os.path.exists(left_folder) and os.path.isdir(left_folder) \n",
    "    assert os.path.exists(right_folder) and os.path.isdir(right_folder) \n",
    "\n",
    "    assert os.path.exists(diff_input_file) and os.path.isfile(diff_input_file) \n",
    "    \n",
    "    fname = func_tool_diff.__name__\n",
    "    \n",
    "    if os.path.exists(output_file) and not overwrite:\n",
    "        log_collect_msg(f'{fname} SKIP existing file {output_file}')\n",
    "        return \n",
    "    \n",
    "    log_collect_msg(f'{fname} is about to create {output_file}')\n",
    "\n",
    "    matches_df = (pd.read_csv(diff_input_file, sep=';')\n",
    "                  .reset_index(drop=True))\n",
    "    \n",
    "    def tool_diff(matches_df, left_folder, right_folder, func_tool_diff):\n",
    "\n",
    "        it = tqdm(matches_df[['File from', 'File to']].iterrows(), total=len(matches_df))\n",
    "        for idx, values  in it:\n",
    "            left_fname, right_fname = values[0:2] \n",
    "            left_file = os.path.join(left_folder, left_fname)\n",
    "            right_file = os.path.join(right_folder, right_fname)\n",
    "            try:\n",
    "                counters = func_tool_diff(left_file, right_file)\n",
    "                assert len(tool_diff_names) == len(counters), 'wrong set of counters:' + counters\n",
    "                yield [left_fname, right_fname] + counters\n",
    "            except:\n",
    "                print('Failed to diff', left_fname, right_fname)\n",
    "\n",
    "    df = (pd.DataFrame(data=tool_diff(matches_df, left_folder, right_folder, func_tool_diff),\n",
    "                        columns=['File from', 'File to'] + tool_diff_names)\n",
    "            .set_index(['File from', 'File to']))\n",
    "\n",
    "    df.to_csv(output_file, sep=\";\")\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        log_collect_msg(f'{fname} has created an output file. Size: {os.stat(output_file).st_size} bytes.')\n",
    "    else:\n",
    "        log_collect_msg(f'{fname} has FAILED to create output file')        \n",
    "    \n",
    "    return df\n",
    "                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gnu_diff_au0bi(left_folder, right_folder, diff_input_file, output_file, overwrite = False):\n",
    "    GNU_DIFF_NAMES = ['Added', 'Deleted', 'Blank_Added', 'Blank_Deleted']\n",
    "\n",
    "    def gnu_diff_files(left_file, right_file):\n",
    "\n",
    "        cmd = f'diff -au0bi \"{left_file}\" \"{right_file}\"'\n",
    "        result = !{cmd}\n",
    "\n",
    "        added, deleted, blank_added, blank_deleted = 0, 0, 0, 0\n",
    "        for line in result[2:]:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"+\"):\n",
    "                if len(line) == 1:\n",
    "                    blank_added += 1\n",
    "                else: \n",
    "                    added += 1\n",
    "            elif line.startswith(\"-\"):\n",
    "                if len(line) == 1:\n",
    "                    blank_deleted += 1\n",
    "                else: \n",
    "                    deleted += 1\n",
    "\n",
    "        return [added, deleted, blank_added, blank_deleted]    \n",
    "    \n",
    "    return collect_tool_diff(left_folder, right_folder, diff_input_file, output_file, GNU_DIFF_NAMES, gnu_diff_files, overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T22:12:42.000027Z",
     "start_time": "2019-04-09T22:11:06.867575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a9135a51d048cf9381abdd2058b47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate profile data for version v2.6.31\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collect_white_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3d3683c5e084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generate profile data for version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnap_folder_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcollect_white_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ws'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'collect_white_space' is not defined"
     ]
    }
   ],
   "source": [
    "for version in tqdm(VERSIONS):\n",
    "    print('generate profile data for version', version)\n",
    "    input_folder = snap_folder_path(version)\n",
    "    collect_blanks(input_folder, tool_file_path(version, 'lines'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILAR_SETS = [set([\".cpp\", \".c\", \".cxx\", \".cc\"]), set([\".hpp\", \".h\", \".hxx\"]), set([\".php\", \".phpt\"])]\n",
    "for diff in tqdm(DIFFS):\n",
    "    v1, v2 = diff\n",
    "    left_folder = snap_folder_path(v1)\n",
    "    right_folder = snap_folder_path(v2)\n",
    "    match_file = tool_file_path(f'{v1}-{v2}', 'match')\n",
    "    diff_file_au0bi = tool_file_path(f'{v1}-{v2}', 'diff-gnu-au0bi')\n",
    "\n",
    "    collect_diff_pairs(left_folder, right_folder, match_file, \n",
    "                            False, None, SIMILAR_SETS, \n",
    "                            compare_paths_longest_folder_seq)\n",
    "    \n",
    "    collect_gnu_diff_au0bi(left_folder, right_folder, \n",
    "                     match_file, diff_file_au0bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_paths(df, col_in='path', col_out='tidy_path'):\n",
    "    paths = df[col_in].str.lower().str.strip()\n",
    "    prefix = os.path.commonpath([f for f in paths])\n",
    "    if prefix:\n",
    "        paths = paths.str[len(prefix) + 1:]\n",
    "    paths = paths.apply(lambda p: p[2:] if p.startswith('./') else p)\n",
    "    df[col_out] = paths\n",
    "    return df\n",
    "\n",
    "def parse_diff_gnu_df(f, v1, v2):\n",
    "    return (pd.read_csv(f, sep=';')\n",
    "               .rename(columns={'File from': 'path_from', 'File to' : 'path_to'})\n",
    "               .pipe(clean_paths, 'path_from', 'tidy_path_from')\n",
    "               .pipe(clean_paths, 'path_to', 'tidy_path_to')\n",
    "               .assign(v1=v1, v2=v2)\n",
    "           )\n",
    "def parse_blanks_df(f, v):\n",
    "    return (pd.read_csv(f, sep=';')\n",
    "               .pipe(clean_paths, 'tidy_path', 'tidy_path')\n",
    "               .assign(version=v)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = pd.concat([parse_blanks_df(tool_file_path(v, 'ws'), v) for v in VERSIONS])\n",
    "\n",
    "profile_df.lines = profile_df.lines.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIFF - collect empty lines diff and use WS to solve common lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnu_diff_df = pd.concat([parse_diff_gnu_df(tool_file_path(f'{v1}-{v2}', 'diff-gnu-au0bi_BLANK'), v1, v2) for v1, v2 in DIFFS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (pd.merge(gnu_diff_df, merged_profile_df, 'inner', left_on=['v1', 'tidy_path_from'], right_on=['version', 'tidy_path'])\n",
    "            .rename(columns={'ws_lines':'ws_lines_from', 'wc_lines':'wc_lines_from', 'empty_lines_count':'empty_lines_count_from'}))\n",
    "merged_df = (pd.merge(merged_df, merged_profile_df, 'inner', left_on=['v2', 'tidy_path_to'], right_on=['version', 'tidy_path'])\n",
    "            .rename(columns={'ws_lines':'ws_lines_to', 'wc_lines':'wc_lines_to', 'empty_lines_count':'empty_lines_count_to'})\n",
    "            .drop(['path_from', 'path_to'], axis=1)\n",
    "            .assign(ext=merged_df['tidy_path_from'].str.rsplit('.', 1, expand=True)[1]))\n",
    "\n",
    "merged_df = merged_df[merged_df['ext'].isin(['h', 'c', 'cpp', 'hpp', 'hxx', 'cxx', 'py', 'cc', 'asm'])]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.assign(ws_common_from = merged_df.ws_lines_from - (merged_df.Deleted + merged_df.Blank_Deleted),\n",
    "                             ws_common_to = merged_df.ws_lines_to - (merged_df.Added + merged_df.Blank_Added),\n",
    "                             ws_common_empty_from = (merged_df.ws_lines_from - merged_df.empty_lines_count_from) - (merged_df.Deleted),\n",
    "                             ws_common_empty_to = (merged_df.ws_lines_to - merged_df.empty_lines_count_to) - (merged_df.Added))\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_df.ws_common_from != merged_df.ws_common_to).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_df.ws_common_empty_from != merged_df.ws_common_empty_to).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((merged_df.ws_lines_from + merged_df.Added - merged_df.Deleted - merged_df.empty_lines_count_from)-(merged_df.ws_lines_to - merged_df.empty_lines_count_to)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((merged_df.ws_lines_from + merged_df.Added - merged_df.Deleted - merged_df.empty_lines_count_from)-(merged_df.ws_lines_to - merged_df.empty_lines_count_to)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((merged_df.ws_lines_from + merged_df.Added + merged_df.Blank_Added - merged_df.Deleted - merged_df.Blank_Deleted) - merged_df.ws_lines_to).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
